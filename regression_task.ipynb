{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "davide_gallon_regression_task.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYncZVOyF8Rb"
      },
      "source": [
        "\n",
        "\n",
        "## Guidelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zs0AM6W_yoMs"
      },
      "source": [
        "* The goal is to train a neural network to approximate an unknown function:\n",
        "$$ \n",
        "f:\\mathbb{R}→\\mathbb{R} \\\\\n",
        "x↦y=f(x) \\\\\n",
        "\\text{network}(x) \\approx f(x)\n",
        "$$\n",
        "* As training point, you only have noisy measures from the target function.\n",
        "$$\n",
        "\\hat{y} = f(x) + noise\n",
        "$$\n",
        "* Consider to create a validation set from you training data, or use a k-fold cross-validation strategy. You may find useful these functions from the `scikit-learn` library:\n",
        "    - [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
        "    - [KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpHoPt5nyocz"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ViQh-gfzxNH"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import KFold\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjV_JeRcwrLC"
      },
      "source": [
        "The following cell of code will download the dataset and make it available in the local folder `regression_dataset`. There are two files:\n",
        "\n",
        "* `regression_dataset/train_data.csv`\n",
        "* `regression_dataset/test_data.csv`\n",
        "\n",
        "Use them to train and test your model. Each row contains two values, respactively the input and the target (label)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXCqDgEsvt96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dc9836a-1258-4114-9254-0cc10fd54729"
      },
      "source": [
        "!wget -P regression_dataset https://gitlab.dei.unipd.it/gadaleta/nnld-2020-21-lab-resources/-/raw/master/homework_1_regression_dataset/train_data.csv\n",
        "!wget -P regression_dataset https://gitlab.dei.unipd.it/gadaleta/nnld-2020-21-lab-resources/-/raw/master/homework_1_regression_dataset/test_data.csv "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-02 10:06:43--  https://gitlab.dei.unipd.it/gadaleta/nnld-2020-21-lab-resources/-/raw/master/homework_1_regression_dataset/train_data.csv\n",
            "Resolving gitlab.dei.unipd.it (gitlab.dei.unipd.it)... 147.162.2.85\n",
            "Connecting to gitlab.dei.unipd.it (gitlab.dei.unipd.it)|147.162.2.85|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3776 (3.7K) [text/plain]\n",
            "Saving to: ‘regression_dataset/train_data.csv’\n",
            "\n",
            "train_data.csv      100%[===================>]   3.69K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-01-02 10:06:44 (99.6 MB/s) - ‘regression_dataset/train_data.csv’ saved [3776/3776]\n",
            "\n",
            "--2021-01-02 10:06:44--  https://gitlab.dei.unipd.it/gadaleta/nnld-2020-21-lab-resources/-/raw/master/homework_1_regression_dataset/test_data.csv\n",
            "Resolving gitlab.dei.unipd.it (gitlab.dei.unipd.it)... 147.162.2.85\n",
            "Connecting to gitlab.dei.unipd.it (gitlab.dei.unipd.it)|147.162.2.85|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3788 (3.7K) [text/plain]\n",
            "Saving to: ‘regression_dataset/test_data.csv’\n",
            "\n",
            "test_data.csv       100%[===================>]   3.70K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-01-02 10:06:45 (95.1 MB/s) - ‘regression_dataset/test_data.csv’ saved [3788/3788]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJRxVBksxsBw"
      },
      "source": [
        "How to load the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OophnNaq7pQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "823b0214-dce0-48cf-c2e7-5ab5a8ecc035"
      },
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(f\"Training device: {device}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-FdEP-JxwEu"
      },
      "source": [
        "train_df = pd.read_csv('regression_dataset/train_data.csv')\n",
        "test_df = pd.read_csv('regression_dataset/test_data.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4FMs2rmzXps"
      },
      "source": [
        "All training points:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXc_6w24zFEB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "71a9e12d-641a-4940-ecdc-23c3d6b77e6b"
      },
      "source": [
        "fig = plt.figure(figsize=(12,8))\n",
        "plt.scatter(train_df.input, train_df.label, label='Training points')\n",
        "plt.xlabel('input')\n",
        "plt.ylabel('label')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vrm5x7eWkWnh"
      },
      "source": [
        "## Transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PfKpQW9rOYl"
      },
      "source": [
        "class ToTensor(object):\n",
        "    \"\"\"Convert sample to Tensors.\"\"\"\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        x, y = sample\n",
        "        return (torch.Tensor([x]).float(),\n",
        "                torch.Tensor([y]).float())"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoBTsdnYtAn0"
      },
      "source": [
        "to_tensor = ToTensor()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPChPe_bklXg"
      },
      "source": [
        "## Classifier Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzPFy2Kp6SOH"
      },
      "source": [
        "class ClassifierDataset(Dataset):\n",
        "\n",
        "  def __init__(self, csv_file, transform=None):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        csv_file (string): Path to the csv file.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.transform = transform\n",
        "    # Read the file and store the content in a pandas DataFrame\n",
        "    self.df = csv_file\n",
        "\n",
        "  def __len__(self):\n",
        "    # The length of the dataset\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    # Our sample is the row at index idx of the dataframe\n",
        "    row = self.df.iloc[idx]\n",
        "    # There are 2 inputs \n",
        "    sample = (row.input, row.label)\n",
        "    if self.transform:\n",
        "        sample = self.transform(sample)\n",
        "    return sample"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxYQW5g_lzGL"
      },
      "source": [
        "train_dataset = ClassifierDataset(train_df,transform=to_tensor)\r\n",
        "test_dataset = ClassifierDataset(test_df,transform=to_tensor)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU_9jz9ilYxl"
      },
      "source": [
        "# Network analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4sKYYlqfyPy"
      },
      "source": [
        "## Network definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL0akrVFArw2"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    \n",
        "    def __init__(self, Nh1):\n",
        "\n",
        "        # Nh1 - Hidden neurons in first layer\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.fc1 = nn.Linear(in_features=1, out_features=Nh1)\n",
        "        self.fc2 = nn.Linear(in_features=Nh1, out_features=2*Nh1)\n",
        "        self.out = nn.Linear(in_features=2*Nh1, out_features=1)\n",
        "        self.act = nn.GELU()\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.act(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.act(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.out(x)\n",
        "        return x"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XLfrLt0krz8"
      },
      "source": [
        "# Early stopping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KpXNUT-vcKZ"
      },
      "source": [
        "class EarlyStopping:\n",
        "    #Early stops the training if validation loss doesn't improve after patience iterations\n",
        "    def __init__(self, patience, delta=0):\n",
        "\n",
        "        #patience (int): How long to wait after last time validation loss improved.\n",
        "        #delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                          \n",
        "        self.patience = patience\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = val_loss\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "        elif score > self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            #print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.counter = 0"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ho8eiy8PDb4I"
      },
      "source": [
        "# Train function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e4SATlQOEhx"
      },
      "source": [
        "def train_epoch(net, device, dataloader, loss_fn, optimizer):\r\n",
        "    # Training mode\r\n",
        "    net.train()\r\n",
        "    train_loss= []\r\n",
        "    for sample_batched in dataloader:\r\n",
        "             x_batch = sample_batched[0].to(device)\r\n",
        "             label_batch = sample_batched[1].to(device)\r\n",
        "             # Forward pass\r\n",
        "             out = net(x_batch)\r\n",
        "             # Compute loss\r\n",
        "             loss = loss_fn(out, label_batch)\r\n",
        "             # Backpropagation\r\n",
        "             net.zero_grad()\r\n",
        "             loss.backward()\r\n",
        "             # Update the weights\r\n",
        "             optimizer.step()\r\n",
        "             # Save train loss for this batch\r\n",
        "             loss_batch = loss.detach().cpu().numpy()\r\n",
        "             train_loss.append(loss_batch)\r\n",
        "    #Save average train loss\r\n",
        "    train_loss = np.mean(train_loss)\r\n",
        "    return train_loss\r\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx4nj-eRfeK5"
      },
      "source": [
        "# Test function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-ABpygQPXHh"
      },
      "source": [
        "def test_epoch(net, device, dataloader, loss_fn):      \r\n",
        "      # Evaluation mode (e.g. disable dropout)\r\n",
        "      net.eval() \r\n",
        "      val_loss= []\r\n",
        "      with torch.no_grad(): # Disable gradient tracking\r\n",
        "           for sample_batched in dataloader:\r\n",
        "             x_batch = sample_batched[0].to(device)\r\n",
        "             label_batch = sample_batched[1].to(device)\r\n",
        "             # Forward pass\r\n",
        "             out = net(x_batch)\r\n",
        "             # Compute loss\r\n",
        "             loss = loss_fn(out, label_batch)\r\n",
        "             # Save val loss for this batch\r\n",
        "             loss_batch = loss.detach().cpu().numpy()\r\n",
        "             val_loss.append(loss_batch)\r\n",
        "      # Save average validation loss\r\n",
        "      val_loss = np.mean(val_loss) \r\n",
        "      return val_loss"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KRHZMArf18j"
      },
      "source": [
        "# Main code\r\n",
        "Using a K-fold cross validation strategy and a grid a search I select the best Hyperparameters on each fold."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vNjRHL5rhRk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2e89d62-77ae-47af-f105-03dd613ba0b9"
      },
      "source": [
        "# matrix of loss and best hyperparameters for each fold\n",
        "best_possibilities=['AVERAGE TRAIN LOSS','AVERAGE VAL LOSS','BATCH SIZE','NUMBER OF HIDDEN1 UNIT',\n",
        "                  'LEARNING RATE','L2 REGULARITAZION WEIGHT','STOPPING EPOCH','NUMBER OF FOLD']\n",
        "# initialize K fold\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
        "fold_num=0\n",
        "\n",
        "# Define the loss function\n",
        "loss_fn = nn.SmoothL1Loss()\n",
        "\n",
        "# K fold cross validation strategy\n",
        "for train, test in kf.split(train_df): \n",
        "\n",
        "  # matrix of all losses and hyperparamters for each fold\n",
        "  fold_results=['AVERAGE TRAIN LOSS','AVERAGE VAL LOSS','BATCH SIZE','NUMBER OF HIDDEN1 UNIT',\n",
        "               'LEARNING RATE','L2 REGULARITAZION WEIGHT','STOPPING EPOCH','NUMBER OF FOLD']\n",
        "\n",
        "  # grid search\n",
        "  for batch in [20,40]:\n",
        "    train_dataloader = DataLoader([train_dataset[x] for x in train], batch_size=batch, shuffle=True, num_workers=0)\n",
        "    val_dataloader   = DataLoader([train_dataset[x] for x in test],   batch_size=len(test), shuffle=False, num_workers=0)\n",
        "   \n",
        "    for learning_rate in [1e-2,1e-3,1e-4]:\n",
        "\n",
        "       for weight in [0,0.00005]:\n",
        "         \n",
        "         for Nhidden1 in [64,128]:\n",
        "\n",
        "          # Initialize the network\n",
        "          torch.manual_seed(0)\n",
        "          net = Net(Nhidden1)\n",
        "          net.to(device)\n",
        "          \n",
        "          # Define the optimizer\n",
        "          optimizer = optim.Adam(net.parameters(), lr=learning_rate,weight_decay=weight)\n",
        "\n",
        "          #Define the early stopping strategy\n",
        "          early_stopping = EarlyStopping(patience=60)\n",
        "\n",
        "          num_epochs = 1000\n",
        "          for epoch_num in range(num_epochs):\n",
        "            # TRAINING\n",
        "            train_loss = train_epoch(net, device, train_dataloader, loss_fn, optimizer)\n",
        "\n",
        "            # VALIDATION\n",
        "            val_loss = test_epoch(net, device, val_dataloader, loss_fn)\n",
        "\n",
        "            # EARLY STOP CHECK\n",
        "            early_stopping(val_loss, net)\n",
        "            \n",
        "            # IF VAL LOSS DOES NOT IMPROVE FOR 60 EPOCHS STOP THE LOOP\n",
        "            if early_stopping.early_stop:\n",
        "              break\n",
        "          \n",
        "          # PRINT RESULTS\n",
        "          stopping_epochs=epoch_num\n",
        "          print(f\"stopping epoch: {stopping_epochs}\")\n",
        "          print(f\"AVERAGE TRAIN LOSS: {train_loss}\")\n",
        "          print(f\"BATCH SIZE: {batch}\")\n",
        "          print(f\"NUMBER OF HIDDEN UNIT: {Nhidden1,Nhidden1*2}\")\n",
        "          print(f\"LEARNING RATE: {learning_rate}\")\n",
        "          print(f\"L2 REGULARITAZION WEIGHT: {weight}\")\n",
        "          print(f\"NUMBER OF K-FOLD: {fold_num}\")\n",
        "          print(f\"AVERAGE VAL LOSS: {val_loss}\")\n",
        "          print('#################')  \n",
        "          \n",
        "          # vector of loss and hyperparameters\n",
        "          result=np.array([train_loss,val_loss,batch,Nhidden1,\n",
        "                              learning_rate,weight,stopping_epochs,fold_num])\n",
        "          # attach results\n",
        "          fold_results=np.vstack((fold_results,result))\n",
        "  \n",
        "\n",
        "  fold_num=fold_num+1\n",
        "  # find best choice in the fold and attach it in best_possibility\n",
        "  best_choice=fold_results[np.argmin(fold_results[1:,1])+1]\n",
        "  best_possibilities=np.vstack((best_possibilities,best_choice))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "stopping epoch: 232\n",
            "AVERAGE TRAIN LOSS: 0.1945393979549408\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 0\n",
            "AVERAGE VAL LOSS: 0.17020028829574585\n",
            "#################\n",
            "stopping epoch: 209\n",
            "AVERAGE TRAIN LOSS: 0.1640596091747284\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 0\n",
            "AVERAGE VAL LOSS: 0.21517863869667053\n",
            "#################\n",
            "stopping epoch: 216\n",
            "AVERAGE TRAIN LOSS: 0.22245018184185028\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 0\n",
            "AVERAGE VAL LOSS: 0.17111681401729584\n",
            "#################\n",
            "stopping epoch: 208\n",
            "AVERAGE TRAIN LOSS: 0.13601015508174896\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 0\n",
            "AVERAGE VAL LOSS: 0.19434373080730438\n",
            "#################\n",
            "stopping epoch: 354\n",
            "AVERAGE TRAIN LOSS: 0.24420619010925293\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 0\n",
            "AVERAGE VAL LOSS: 0.23952224850654602\n",
            "#################\n",
            "stopping epoch: 413\n",
            "AVERAGE TRAIN LOSS: 0.18806076049804688\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 0\n",
            "AVERAGE VAL LOSS: 0.15537700057029724\n",
            "#################\n",
            "stopping epoch: 354\n",
            "AVERAGE TRAIN LOSS: 0.2443404346704483\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 0\n",
            "AVERAGE VAL LOSS: 0.24015939235687256\n",
            "#################\n",
            "stopping epoch: 413\n",
            "AVERAGE TRAIN LOSS: 0.18985585868358612\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 0\n",
            "AVERAGE VAL LOSS: 0.1566493958234787\n",
            "#################\n",
            "stopping epoch: 484\n",
            "AVERAGE TRAIN LOSS: 0.5313847661018372\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 0\n",
            "AVERAGE VAL LOSS: 0.6655554175376892\n",
            "#################\n",
            "stopping epoch: 958\n",
            "AVERAGE TRAIN LOSS: 0.3195250630378723\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 0\n",
            "AVERAGE VAL LOSS: 0.280410498380661\n",
            "#################\n",
            "stopping epoch: 484\n",
            "AVERAGE TRAIN LOSS: 0.5314383506774902\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 0\n",
            "AVERAGE VAL LOSS: 0.6657299995422363\n",
            "#################\n",
            "stopping epoch: 958\n",
            "AVERAGE TRAIN LOSS: 0.32016193866729736\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 0\n",
            "AVERAGE VAL LOSS: 0.28088656067848206\n",
            "#################\n",
            "stopping epoch: 304\n",
            "AVERAGE TRAIN LOSS: 0.2624792158603668\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 0\n",
            "AVERAGE VAL LOSS: 0.21150198578834534\n",
            "#################\n",
            "stopping epoch: 246\n",
            "AVERAGE TRAIN LOSS: 0.15302565693855286\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 0\n",
            "AVERAGE VAL LOSS: 0.18390730023384094\n",
            "#################\n",
            "stopping epoch: 176\n",
            "AVERAGE TRAIN LOSS: 0.31149110198020935\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 0\n",
            "AVERAGE VAL LOSS: 0.32153886556625366\n",
            "#################\n",
            "stopping epoch: 238\n",
            "AVERAGE TRAIN LOSS: 0.19749657809734344\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 0\n",
            "AVERAGE VAL LOSS: 0.21327021718025208\n",
            "#################\n",
            "stopping epoch: 441\n",
            "AVERAGE TRAIN LOSS: 0.2770985960960388\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 0\n",
            "AVERAGE VAL LOSS: 0.27624937891960144\n",
            "#################\n",
            "stopping epoch: 606\n",
            "AVERAGE TRAIN LOSS: 0.19465512037277222\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 0\n",
            "AVERAGE VAL LOSS: 0.16099314391613007\n",
            "#################\n",
            "stopping epoch: 441\n",
            "AVERAGE TRAIN LOSS: 0.2774537205696106\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 0\n",
            "AVERAGE VAL LOSS: 0.2769721746444702\n",
            "#################\n",
            "stopping epoch: 606\n",
            "AVERAGE TRAIN LOSS: 0.1958487629890442\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 0\n",
            "AVERAGE VAL LOSS: 0.16261525452136993\n",
            "#################\n",
            "stopping epoch: 561\n",
            "AVERAGE TRAIN LOSS: 0.5258544683456421\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 0\n",
            "AVERAGE VAL LOSS: 0.7236275672912598\n",
            "#################\n",
            "stopping epoch: 999\n",
            "AVERAGE TRAIN LOSS: 0.317676842212677\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 0\n",
            "AVERAGE VAL LOSS: 0.3493667542934418\n",
            "#################\n",
            "stopping epoch: 561\n",
            "AVERAGE TRAIN LOSS: 0.5259432792663574\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 0\n",
            "AVERAGE VAL LOSS: 0.7237405180931091\n",
            "#################\n",
            "stopping epoch: 999\n",
            "AVERAGE TRAIN LOSS: 0.31808823347091675\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 0\n",
            "AVERAGE VAL LOSS: 0.3499797284603119\n",
            "#################\n",
            "stopping epoch: 165\n",
            "AVERAGE TRAIN LOSS: 0.19166427850723267\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 1\n",
            "AVERAGE VAL LOSS: 0.19722974300384521\n",
            "#################\n",
            "stopping epoch: 170\n",
            "AVERAGE TRAIN LOSS: 0.18420878052711487\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 1\n",
            "AVERAGE VAL LOSS: 0.24728846549987793\n",
            "#################\n",
            "stopping epoch: 227\n",
            "AVERAGE TRAIN LOSS: 0.1482076197862625\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 1\n",
            "AVERAGE VAL LOSS: 0.26341724395751953\n",
            "#################\n",
            "stopping epoch: 170\n",
            "AVERAGE TRAIN LOSS: 0.18844856321811676\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 1\n",
            "AVERAGE VAL LOSS: 0.2776244580745697\n",
            "#################\n",
            "stopping epoch: 604\n",
            "AVERAGE TRAIN LOSS: 0.2219460904598236\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 1\n",
            "AVERAGE VAL LOSS: 0.21156354248523712\n",
            "#################\n",
            "stopping epoch: 309\n",
            "AVERAGE TRAIN LOSS: 0.21695008873939514\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 1\n",
            "AVERAGE VAL LOSS: 0.17669987678527832\n",
            "#################\n",
            "stopping epoch: 604\n",
            "AVERAGE TRAIN LOSS: 0.22261075675487518\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 1\n",
            "AVERAGE VAL LOSS: 0.21256713569164276\n",
            "#################\n",
            "stopping epoch: 309\n",
            "AVERAGE TRAIN LOSS: 0.2186460644006729\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 1\n",
            "AVERAGE VAL LOSS: 0.17839737236499786\n",
            "#################\n",
            "stopping epoch: 999\n",
            "AVERAGE TRAIN LOSS: 0.40666091442108154\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 1\n",
            "AVERAGE VAL LOSS: 0.46329036355018616\n",
            "#################\n",
            "stopping epoch: 999\n",
            "AVERAGE TRAIN LOSS: 0.2418515980243683\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 1\n",
            "AVERAGE VAL LOSS: 0.23516221344470978\n",
            "#################\n",
            "stopping epoch: 999\n",
            "AVERAGE TRAIN LOSS: 0.406987726688385\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 1\n",
            "AVERAGE VAL LOSS: 0.4635566771030426\n",
            "#################\n",
            "stopping epoch: 999\n",
            "AVERAGE TRAIN LOSS: 0.24229907989501953\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 1\n",
            "AVERAGE VAL LOSS: 0.23574736714363098\n",
            "#################\n",
            "stopping epoch: 257\n",
            "AVERAGE TRAIN LOSS: 0.21998153626918793\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 1\n",
            "AVERAGE VAL LOSS: 0.22788596153259277\n",
            "#################\n",
            "stopping epoch: 246\n",
            "AVERAGE TRAIN LOSS: 0.17032599449157715\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 1\n",
            "AVERAGE VAL LOSS: 0.13428504765033722\n",
            "#################\n",
            "stopping epoch: 342\n",
            "AVERAGE TRAIN LOSS: 0.2690613865852356\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 1\n",
            "AVERAGE VAL LOSS: 0.25455528497695923\n",
            "#################\n",
            "stopping epoch: 205\n",
            "AVERAGE TRAIN LOSS: 0.1946500539779663\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 1\n",
            "AVERAGE VAL LOSS: 0.19349965453147888\n",
            "#################\n",
            "stopping epoch: 383\n",
            "AVERAGE TRAIN LOSS: 0.3203185498714447\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 1\n",
            "AVERAGE VAL LOSS: 0.24241729080677032\n",
            "#################\n",
            "stopping epoch: 422\n",
            "AVERAGE TRAIN LOSS: 0.2695189118385315\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 1\n",
            "AVERAGE VAL LOSS: 0.1509028822183609\n",
            "#################\n",
            "stopping epoch: 383\n",
            "AVERAGE TRAIN LOSS: 0.3203822374343872\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 1\n",
            "AVERAGE VAL LOSS: 0.2426767647266388\n",
            "#################\n",
            "stopping epoch: 422\n",
            "AVERAGE TRAIN LOSS: 0.27080297470092773\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 1\n",
            "AVERAGE VAL LOSS: 0.15155772864818573\n",
            "#################\n",
            "stopping epoch: 833\n",
            "AVERAGE TRAIN LOSS: 0.6260032653808594\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 1\n",
            "AVERAGE VAL LOSS: 0.572833240032196\n",
            "#################\n",
            "stopping epoch: 999\n",
            "AVERAGE TRAIN LOSS: 0.3613196015357971\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 1\n",
            "AVERAGE VAL LOSS: 0.3280218839645386\n",
            "#################\n",
            "stopping epoch: 833\n",
            "AVERAGE TRAIN LOSS: 0.6260880827903748\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 1\n",
            "AVERAGE VAL LOSS: 0.5728745460510254\n",
            "#################\n",
            "stopping epoch: 999\n",
            "AVERAGE TRAIN LOSS: 0.3616000711917877\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 1\n",
            "AVERAGE VAL LOSS: 0.3284846842288971\n",
            "#################\n",
            "stopping epoch: 168\n",
            "AVERAGE TRAIN LOSS: 0.20907074213027954\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 2\n",
            "AVERAGE VAL LOSS: 0.2467106133699417\n",
            "#################\n",
            "stopping epoch: 156\n",
            "AVERAGE TRAIN LOSS: 0.24375201761722565\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 2\n",
            "AVERAGE VAL LOSS: 0.227505162358284\n",
            "#################\n",
            "stopping epoch: 145\n",
            "AVERAGE TRAIN LOSS: 0.21374303102493286\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 2\n",
            "AVERAGE VAL LOSS: 0.13338212668895721\n",
            "#################\n",
            "stopping epoch: 157\n",
            "AVERAGE TRAIN LOSS: 0.2622145116329193\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 2\n",
            "AVERAGE VAL LOSS: 0.16132783889770508\n",
            "#################\n",
            "stopping epoch: 534\n",
            "AVERAGE TRAIN LOSS: 0.2298864871263504\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 2\n",
            "AVERAGE VAL LOSS: 0.15982352197170258\n",
            "#################\n",
            "stopping epoch: 302\n",
            "AVERAGE TRAIN LOSS: 0.24288678169250488\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 2\n",
            "AVERAGE VAL LOSS: 0.18215058743953705\n",
            "#################\n",
            "stopping epoch: 534\n",
            "AVERAGE TRAIN LOSS: 0.23221871256828308\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 2\n",
            "AVERAGE VAL LOSS: 0.15966682136058807\n",
            "#################\n",
            "stopping epoch: 302\n",
            "AVERAGE TRAIN LOSS: 0.24689292907714844\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 2\n",
            "AVERAGE VAL LOSS: 0.18194691836833954\n",
            "#################\n",
            "stopping epoch: 973\n",
            "AVERAGE TRAIN LOSS: 0.4528997242450714\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 2\n",
            "AVERAGE VAL LOSS: 0.4066328704357147\n",
            "#################\n",
            "stopping epoch: 999\n",
            "AVERAGE TRAIN LOSS: 0.34323978424072266\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 2\n",
            "AVERAGE VAL LOSS: 0.16802476346492767\n",
            "#################\n",
            "stopping epoch: 973\n",
            "AVERAGE TRAIN LOSS: 0.4530615210533142\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 2\n",
            "AVERAGE VAL LOSS: 0.40716204047203064\n",
            "#################\n",
            "stopping epoch: 999\n",
            "AVERAGE TRAIN LOSS: 0.3435710072517395\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 2\n",
            "AVERAGE VAL LOSS: 0.16899707913398743\n",
            "#################\n",
            "stopping epoch: 249\n",
            "AVERAGE TRAIN LOSS: 0.20125529170036316\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 2\n",
            "AVERAGE VAL LOSS: 0.17249344289302826\n",
            "#################\n",
            "stopping epoch: 209\n",
            "AVERAGE TRAIN LOSS: 0.18729381263256073\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 2\n",
            "AVERAGE VAL LOSS: 0.119353286921978\n",
            "#################\n",
            "stopping epoch: 249\n",
            "AVERAGE TRAIN LOSS: 0.1984272599220276\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 2\n",
            "AVERAGE VAL LOSS: 0.1605546623468399\n",
            "#################\n",
            "stopping epoch: 156\n",
            "AVERAGE TRAIN LOSS: 0.21407578885555267\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 2\n",
            "AVERAGE VAL LOSS: 0.1303960531949997\n",
            "#################\n",
            "stopping epoch: 632\n",
            "AVERAGE TRAIN LOSS: 0.2496553361415863\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 2\n",
            "AVERAGE VAL LOSS: 0.12934713065624237\n",
            "#################\n",
            "stopping epoch: 337\n",
            "AVERAGE TRAIN LOSS: 0.23686541616916656\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 2\n",
            "AVERAGE VAL LOSS: 0.1631736308336258\n",
            "#################\n",
            "stopping epoch: 632\n",
            "AVERAGE TRAIN LOSS: 0.25023797154426575\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 2\n",
            "AVERAGE VAL LOSS: 0.1294441819190979\n",
            "#################\n",
            "stopping epoch: 338\n",
            "AVERAGE TRAIN LOSS: 0.27889159321784973\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 2\n",
            "AVERAGE VAL LOSS: 0.1468767374753952\n",
            "#################\n",
            "stopping epoch: 928\n",
            "AVERAGE TRAIN LOSS: 0.49208593368530273\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 2\n",
            "AVERAGE VAL LOSS: 0.4938031733036041\n",
            "#################\n",
            "stopping epoch: 548\n",
            "AVERAGE TRAIN LOSS: 0.46854761242866516\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 2\n",
            "AVERAGE VAL LOSS: 0.4574565887451172\n",
            "#################\n",
            "stopping epoch: 928\n",
            "AVERAGE TRAIN LOSS: 0.4923514425754547\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 2\n",
            "AVERAGE VAL LOSS: 0.4939865171909332\n",
            "#################\n",
            "stopping epoch: 548\n",
            "AVERAGE TRAIN LOSS: 0.46875709295272827\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 2\n",
            "AVERAGE VAL LOSS: 0.4578433632850647\n",
            "#################\n",
            "stopping epoch: 182\n",
            "AVERAGE TRAIN LOSS: 0.21896816790103912\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 3\n",
            "AVERAGE VAL LOSS: 0.19915734231472015\n",
            "#################\n",
            "stopping epoch: 142\n",
            "AVERAGE TRAIN LOSS: 0.2255447953939438\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 3\n",
            "AVERAGE VAL LOSS: 0.3581240177154541\n",
            "#################\n",
            "stopping epoch: 182\n",
            "AVERAGE TRAIN LOSS: 0.22536692023277283\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 3\n",
            "AVERAGE VAL LOSS: 0.20598821341991425\n",
            "#################\n",
            "stopping epoch: 176\n",
            "AVERAGE TRAIN LOSS: 0.22904044389724731\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 3\n",
            "AVERAGE VAL LOSS: 0.31655868887901306\n",
            "#################\n",
            "stopping epoch: 501\n",
            "AVERAGE TRAIN LOSS: 0.2083170861005783\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 3\n",
            "AVERAGE VAL LOSS: 0.16498152911663055\n",
            "#################\n",
            "stopping epoch: 493\n",
            "AVERAGE TRAIN LOSS: 0.2261105477809906\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 3\n",
            "AVERAGE VAL LOSS: 0.13517281413078308\n",
            "#################\n",
            "stopping epoch: 501\n",
            "AVERAGE TRAIN LOSS: 0.2096020132303238\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 3\n",
            "AVERAGE VAL LOSS: 0.16641049087047577\n",
            "#################\n",
            "stopping epoch: 493\n",
            "AVERAGE TRAIN LOSS: 0.22565720975399017\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 3\n",
            "AVERAGE VAL LOSS: 0.13473336398601532\n",
            "#################\n",
            "stopping epoch: 881\n",
            "AVERAGE TRAIN LOSS: 0.5948258638381958\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 3\n",
            "AVERAGE VAL LOSS: 0.41785335540771484\n",
            "#################\n",
            "stopping epoch: 558\n",
            "AVERAGE TRAIN LOSS: 0.3975546658039093\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 3\n",
            "AVERAGE VAL LOSS: 0.399167537689209\n",
            "#################\n",
            "stopping epoch: 881\n",
            "AVERAGE TRAIN LOSS: 0.5949928164482117\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 3\n",
            "AVERAGE VAL LOSS: 0.41823506355285645\n",
            "#################\n",
            "stopping epoch: 558\n",
            "AVERAGE TRAIN LOSS: 0.3979073166847229\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 3\n",
            "AVERAGE VAL LOSS: 0.39982903003692627\n",
            "#################\n",
            "stopping epoch: 274\n",
            "AVERAGE TRAIN LOSS: 0.24002555012702942\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 3\n",
            "AVERAGE VAL LOSS: 0.1380990445613861\n",
            "#################\n",
            "stopping epoch: 304\n",
            "AVERAGE TRAIN LOSS: 0.18311241269111633\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 3\n",
            "AVERAGE VAL LOSS: 0.19490225613117218\n",
            "#################\n",
            "stopping epoch: 207\n",
            "AVERAGE TRAIN LOSS: 0.2085595428943634\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 3\n",
            "AVERAGE VAL LOSS: 0.13034413754940033\n",
            "#################\n",
            "stopping epoch: 228\n",
            "AVERAGE TRAIN LOSS: 0.20941108465194702\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 3\n",
            "AVERAGE VAL LOSS: 0.1971101015806198\n",
            "#################\n",
            "stopping epoch: 505\n",
            "AVERAGE TRAIN LOSS: 0.24645376205444336\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 3\n",
            "AVERAGE VAL LOSS: 0.1838948279619217\n",
            "#################\n",
            "stopping epoch: 361\n",
            "AVERAGE TRAIN LOSS: 0.2898070812225342\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 3\n",
            "AVERAGE VAL LOSS: 0.17277313768863678\n",
            "#################\n",
            "stopping epoch: 505\n",
            "AVERAGE TRAIN LOSS: 0.24717532098293304\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 3\n",
            "AVERAGE VAL LOSS: 0.18402394652366638\n",
            "#################\n",
            "stopping epoch: 247\n",
            "AVERAGE TRAIN LOSS: 0.25618311762809753\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 3\n",
            "AVERAGE VAL LOSS: 0.19309958815574646\n",
            "#################\n",
            "stopping epoch: 821\n",
            "AVERAGE TRAIN LOSS: 0.6020078063011169\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 3\n",
            "AVERAGE VAL LOSS: 0.5009803771972656\n",
            "#################\n",
            "stopping epoch: 581\n",
            "AVERAGE TRAIN LOSS: 0.5759611129760742\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 3\n",
            "AVERAGE VAL LOSS: 0.5138466954231262\n",
            "#################\n",
            "stopping epoch: 821\n",
            "AVERAGE TRAIN LOSS: 0.6021618843078613\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 3\n",
            "AVERAGE VAL LOSS: 0.501060426235199\n",
            "#################\n",
            "stopping epoch: 581\n",
            "AVERAGE TRAIN LOSS: 0.5760667324066162\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 3\n",
            "AVERAGE VAL LOSS: 0.5142309069633484\n",
            "#################\n",
            "stopping epoch: 436\n",
            "AVERAGE TRAIN LOSS: 0.18239831924438477\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 4\n",
            "AVERAGE VAL LOSS: 0.11326179653406143\n",
            "#################\n",
            "stopping epoch: 197\n",
            "AVERAGE TRAIN LOSS: 0.2176368534564972\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 4\n",
            "AVERAGE VAL LOSS: 0.13822633028030396\n",
            "#################\n",
            "stopping epoch: 344\n",
            "AVERAGE TRAIN LOSS: 0.17686296999454498\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 4\n",
            "AVERAGE VAL LOSS: 0.11290065199136734\n",
            "#################\n",
            "stopping epoch: 215\n",
            "AVERAGE TRAIN LOSS: 0.29885250329971313\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 4\n",
            "AVERAGE VAL LOSS: 0.17738769948482513\n",
            "#################\n",
            "stopping epoch: 427\n",
            "AVERAGE TRAIN LOSS: 0.2931554913520813\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 4\n",
            "AVERAGE VAL LOSS: 0.195447638630867\n",
            "#################\n",
            "stopping epoch: 389\n",
            "AVERAGE TRAIN LOSS: 0.2547655999660492\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 4\n",
            "AVERAGE VAL LOSS: 0.18768011033535004\n",
            "#################\n",
            "stopping epoch: 427\n",
            "AVERAGE TRAIN LOSS: 0.29434674978256226\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 4\n",
            "AVERAGE VAL LOSS: 0.19488058984279633\n",
            "#################\n",
            "stopping epoch: 389\n",
            "AVERAGE TRAIN LOSS: 0.25560879707336426\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 4\n",
            "AVERAGE VAL LOSS: 0.18766899406909943\n",
            "#################\n",
            "stopping epoch: 400\n",
            "AVERAGE TRAIN LOSS: 0.6607844829559326\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 4\n",
            "AVERAGE VAL LOSS: 0.44239941239356995\n",
            "#################\n",
            "stopping epoch: 999\n",
            "AVERAGE TRAIN LOSS: 0.32045188546180725\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 4\n",
            "AVERAGE VAL LOSS: 0.19549600780010223\n",
            "#################\n",
            "stopping epoch: 400\n",
            "AVERAGE TRAIN LOSS: 0.6609027981758118\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 4\n",
            "AVERAGE VAL LOSS: 0.44268250465393066\n",
            "#################\n",
            "stopping epoch: 999\n",
            "AVERAGE TRAIN LOSS: 0.3208748698234558\n",
            "BATCH SIZE: 20\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 4\n",
            "AVERAGE VAL LOSS: 0.19586478173732758\n",
            "#################\n",
            "stopping epoch: 349\n",
            "AVERAGE TRAIN LOSS: 0.1761166751384735\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 4\n",
            "AVERAGE VAL LOSS: 0.12685725092887878\n",
            "#################\n",
            "stopping epoch: 309\n",
            "AVERAGE TRAIN LOSS: 0.16170915961265564\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 4\n",
            "AVERAGE VAL LOSS: 0.1736099272966385\n",
            "#################\n",
            "stopping epoch: 349\n",
            "AVERAGE TRAIN LOSS: 0.17806203663349152\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 4\n",
            "AVERAGE VAL LOSS: 0.11635053157806396\n",
            "#################\n",
            "stopping epoch: 331\n",
            "AVERAGE TRAIN LOSS: 0.18345674872398376\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.01\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 4\n",
            "AVERAGE VAL LOSS: 0.12281258404254913\n",
            "#################\n",
            "stopping epoch: 659\n",
            "AVERAGE TRAIN LOSS: 0.2619416117668152\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 4\n",
            "AVERAGE VAL LOSS: 0.15485186874866486\n",
            "#################\n",
            "stopping epoch: 395\n",
            "AVERAGE TRAIN LOSS: 0.27972444891929626\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 4\n",
            "AVERAGE VAL LOSS: 0.1721816509962082\n",
            "#################\n",
            "stopping epoch: 659\n",
            "AVERAGE TRAIN LOSS: 0.2626552879810333\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 4\n",
            "AVERAGE VAL LOSS: 0.15568624436855316\n",
            "#################\n",
            "stopping epoch: 395\n",
            "AVERAGE TRAIN LOSS: 0.2796598970890045\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 4\n",
            "AVERAGE VAL LOSS: 0.1733010858297348\n",
            "#################\n",
            "stopping epoch: 999\n",
            "AVERAGE TRAIN LOSS: 0.4547748863697052\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 4\n",
            "AVERAGE VAL LOSS: 0.33770883083343506\n",
            "#################\n",
            "stopping epoch: 999\n",
            "AVERAGE TRAIN LOSS: 0.4197620153427124\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 0\n",
            "NUMBER OF K-FOLD: 4\n",
            "AVERAGE VAL LOSS: 0.22918248176574707\n",
            "#################\n",
            "stopping epoch: 999\n",
            "AVERAGE TRAIN LOSS: 0.4551042318344116\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (64, 128)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 4\n",
            "AVERAGE VAL LOSS: 0.3376207649707794\n",
            "#################\n",
            "stopping epoch: 999\n",
            "AVERAGE TRAIN LOSS: 0.4203995168209076\n",
            "BATCH SIZE: 40\n",
            "NUMBER OF HIDDEN UNIT: (128, 256)\n",
            "LEARNING RATE: 0.0001\n",
            "L2 REGULARITAZION WEIGHT: 5e-05\n",
            "NUMBER OF K-FOLD: 4\n",
            "AVERAGE VAL LOSS: 0.22959642112255096\n",
            "#################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogS-rBi7SiFE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "e20e5f90-2f10-4773-ef61-a1cad8542426"
      },
      "source": [
        "# matrix of results\r\n",
        "pd.DataFrame(best_possibilities[1:,:], columns=best_possibilities[0,:])\r\n",
        "\r\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AVERAGE TRAIN LOSS</th>\n",
              "      <th>AVERAGE VAL LOSS</th>\n",
              "      <th>BATCH SIZE</th>\n",
              "      <th>NUMBER OF HIDDEN1 UNIT</th>\n",
              "      <th>LEARNING RATE</th>\n",
              "      <th>L2 REGULARITAZION WEIGHT</th>\n",
              "      <th>STOPPING EPOCH</th>\n",
              "      <th>NUMBER OF FOLD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.18806076049804688</td>\n",
              "      <td>0.15537700057029724</td>\n",
              "      <td>20.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.0</td>\n",
              "      <td>413.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.17032599449157715</td>\n",
              "      <td>0.13428504765033722</td>\n",
              "      <td>40.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>246.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.18729381263256073</td>\n",
              "      <td>0.119353286921978</td>\n",
              "      <td>40.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.2085595428943634</td>\n",
              "      <td>0.13034413754940033</td>\n",
              "      <td>40.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>5e-05</td>\n",
              "      <td>207.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.17686296999454498</td>\n",
              "      <td>0.11290065199136734</td>\n",
              "      <td>20.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>5e-05</td>\n",
              "      <td>344.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    AVERAGE TRAIN LOSS     AVERAGE VAL LOSS  ... STOPPING EPOCH NUMBER OF FOLD\n",
              "0  0.18806076049804688  0.15537700057029724  ...          413.0            0.0\n",
              "1  0.17032599449157715  0.13428504765033722  ...          246.0            1.0\n",
              "2  0.18729381263256073    0.119353286921978  ...          209.0            2.0\n",
              "3   0.2085595428943634  0.13034413754940033  ...          207.0            3.0\n",
              "4  0.17686296999454498  0.11290065199136734  ...          344.0            4.0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYl7VLnaDcAZ"
      },
      "source": [
        "## Analyze hyperparameters performance in the training dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nE256vewf0a"
      },
      "source": [
        "To be sure that hyperparameters have a good performance in the entire training dataset I take the mean of all the validation losses calculated in each fold."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLYct1H3y8JL",
        "outputId": "84685649-b479-4418-f3d1-ebb94110585c"
      },
      "source": [
        "for i in range(5):\r\n",
        " # define hyperparameters\r\n",
        " batch_size = int(float(best_possibilities[i+1,2]))\r\n",
        " Nh1 = int(float(best_possibilities[i+1,3]))\r\n",
        " lr = float(best_possibilities[i+1,4])\r\n",
        " weight = float(best_possibilities[i+1,5])\r\n",
        " stopping_epochs = int(float(best_possibilities[i+1,6]))\r\n",
        " \r\n",
        " # vector of losses for all folds\r\n",
        " total_train_loss = []\r\n",
        " total_val_loss = []\r\n",
        "\r\n",
        " print('#################')\r\n",
        " print('#################')\r\n",
        " print('#################')\r\n",
        " print('Model with')\r\n",
        " print(f\"BATCH SIZE: {batch_size},  NUMBER OF HIDDEN UNIT: {Nh1, Nh1*2},  LEARNING RATE: {lr},  L2 REGULARITAZION WEIGHT: {weight}\")\r\n",
        " \r\n",
        " for train,test in kf.split(train_df):\r\n",
        "  train_dataloader = DataLoader([train_dataset[x] for x in train], batch_size=batch_size, shuffle=True, num_workers=0)\r\n",
        "  val_dataloader = DataLoader([train_dataset[x] for x in test], batch_size=len(test), shuffle=False, num_workers=0)\r\n",
        "  \r\n",
        "  # initialize network\r\n",
        "  torch.manual_seed(0)\r\n",
        "  net = Net(Nh1)\r\n",
        "  net.to(device)\r\n",
        "\r\n",
        "  # optimizer\r\n",
        "  optimizer = optim.Adam(net.parameters(), lr=lr ,weight_decay=weight)\r\n",
        "\r\n",
        "  #Define the early stopping strategy\r\n",
        "  early_stopping = EarlyStopping(patience=60)\r\n",
        "  \r\n",
        "  # training loop\r\n",
        "  num_epochs = 500\r\n",
        "  for epoch_num in range(num_epochs):\r\n",
        "      train_loss = train_epoch(net, device, train_dataloader, loss_fn, optimizer)\r\n",
        "      val_loss = test_epoch(net, device, val_dataloader, loss_fn)\r\n",
        "\r\n",
        "      # EARLY STOP CHECK\r\n",
        "      early_stopping(val_loss, net)\r\n",
        "            \r\n",
        "      # IF VAL LOSS DOES NOT IMPROVE AFTER 60 EPOCHS STOP THE LOOP\r\n",
        "      if early_stopping.early_stop:\r\n",
        "          break\r\n",
        "\r\n",
        "  # append losses  \r\n",
        "  total_train_loss.append(train_loss)\r\n",
        "  total_val_loss.append(val_loss)\r\n",
        " \r\n",
        " # calculate the mean\r\n",
        " mean_train_loss=np.mean(total_train_loss)\r\n",
        " mean_val_loss=np.mean(total_val_loss)\r\n",
        " print(f\"AVERAGE ON ALL FOLDS TRAIN LOSS: {mean_train_loss}\")\r\n",
        " print(f\"AVERAGE ON ALL FOLDS VAL LOSS: {mean_val_loss}\")\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        " "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#################\n",
            "#################\n",
            "#################\n",
            "Model with\n",
            "BATCH SIZE: 20,  NUMBER OF HIDDEN UNIT: (128, 256),  LEARNING RATE: 0.001,  L2 REGULARITAZION WEIGHT: 0.0\n",
            "AVERAGE ON ALL FOLDS TRAIN LOSS: 0.2257547676563263\n",
            "AVERAGE ON ALL FOLDS VAL LOSS: 0.1674160659313202\n",
            "#################\n",
            "#################\n",
            "#################\n",
            "Model with\n",
            "BATCH SIZE: 40,  NUMBER OF HIDDEN UNIT: (128, 256),  LEARNING RATE: 0.01,  L2 REGULARITAZION WEIGHT: 0.0\n",
            "AVERAGE ON ALL FOLDS TRAIN LOSS: 0.1710934191942215\n",
            "AVERAGE ON ALL FOLDS VAL LOSS: 0.16121156513690948\n",
            "#################\n",
            "#################\n",
            "#################\n",
            "Model with\n",
            "BATCH SIZE: 40,  NUMBER OF HIDDEN UNIT: (128, 256),  LEARNING RATE: 0.01,  L2 REGULARITAZION WEIGHT: 0.0\n",
            "AVERAGE ON ALL FOLDS TRAIN LOSS: 0.1710934191942215\n",
            "AVERAGE ON ALL FOLDS VAL LOSS: 0.16121156513690948\n",
            "#################\n",
            "#################\n",
            "#################\n",
            "Model with\n",
            "BATCH SIZE: 40,  NUMBER OF HIDDEN UNIT: (64, 128),  LEARNING RATE: 0.01,  L2 REGULARITAZION WEIGHT: 5e-05\n",
            "AVERAGE ON ALL FOLDS TRAIN LOSS: 0.23312027752399445\n",
            "AVERAGE ON ALL FOLDS VAL LOSS: 0.19666869938373566\n",
            "#################\n",
            "#################\n",
            "#################\n",
            "Model with\n",
            "BATCH SIZE: 20,  NUMBER OF HIDDEN UNIT: (64, 128),  LEARNING RATE: 0.01,  L2 REGULARITAZION WEIGHT: 5e-05\n",
            "AVERAGE ON ALL FOLDS TRAIN LOSS: 0.19732613861560822\n",
            "AVERAGE ON ALL FOLDS VAL LOSS: 0.17736102640628815\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ADDV-RUlLaJ"
      },
      "source": [
        "# Final training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6mCvqkQkOD-",
        "outputId": "0e504eef-bd8a-42e9-fbfe-e7f02490ae85"
      },
      "source": [
        " # select index with best averaged results\r\n",
        " i=1\r\n",
        "\r\n",
        " # select hyperparameters\r\n",
        " batch_size = int(float(best_possibilities[i+1,2]))\r\n",
        " Nh1 = int(float(best_possibilities[i+1,3]))\r\n",
        " lr = float(best_possibilities[i+1,4])\r\n",
        " weight = float(best_possibilities[i+1,5])\r\n",
        " stopping_epochs = int(float(best_possibilities[i+1,6]))\r\n",
        "\r\n",
        " print('#################')\r\n",
        " print('#################')\r\n",
        " print('#################')\r\n",
        " print('Model with')\r\n",
        " print(f\"BATCH SIZE: {batch},  NUMBER OF HIDDEN UNIT: {Nh1,Nh1*2}, LEARNING RATE: {lr},  L2 REGULARITAZION WEIGHT: {weight}\")\r\n",
        "\r\n",
        " train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\r\n",
        " test_dataloader = DataLoader(test_dataset, batch_size=len(test), shuffle=False, num_workers=0)\r\n",
        "\r\n",
        " # initialize network\r\n",
        " torch.manual_seed(0)\r\n",
        " loss_fn = nn.SmoothL1Loss()\r\n",
        " net = Net(Nh1)\r\n",
        " net.to(device)\r\n",
        "\r\n",
        " # optimizer\r\n",
        " optimizer = optim.Adam(net.parameters(), lr=lr ,weight_decay=weight)      \r\n",
        " \r\n",
        " # training loop\r\n",
        " num_epochs = 500\r\n",
        " for epoch_num in range(num_epochs):\r\n",
        "      train_loss = train_epoch(net, device, train_dataloader, loss_fn, optimizer)\r\n",
        " \r\n",
        " # test loss\r\n",
        " test_loss = test_epoch(net, device, test_dataloader, loss_fn)\r\n",
        " print(f\"AVERAGE TRAIN LOSS: {train_loss}\")\r\n",
        " print(f\"TEST LOSS: {test_loss}\")\r\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#################\n",
            "#################\n",
            "#################\n",
            "Model with\n",
            "BATCH SIZE: 40,  NUMBER OF HIDDEN UNIT: (128, 256), LEARNING RATE: 0.01,  L2 REGULARITAZION WEIGHT: 0.0\n",
            "AVERAGE TRAIN LOSS: 0.14228267967700958\n",
            "TEST LOSS: 0.03227825462818146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJZEdObDDjDN"
      },
      "source": [
        "# Test the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-WRsra24B9G",
        "outputId": "9a60d606-cea7-4f13-b718-7d015639e9ab"
      },
      "source": [
        "x_vec = torch.linspace(-5,5,1000)\n",
        "x_vec = x_vec.to(device)\n",
        "x_vec = x_vec.unsqueeze(-1)\n",
        "print(f\"Input shape: {x_vec.shape}\")\n",
        "\n",
        "# Network output\n",
        "with torch.no_grad():\n",
        "  y_vec = net(x_vec)\n",
        "print(f\"Output shape: {y_vec.shape}\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([1000, 1])\n",
            "Output shape: torch.Size([1000, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "QKrFpnLc7m5V",
        "outputId": "759f0aec-7228-4dd8-9165-345d633f004e"
      },
      "source": [
        "x_vec = x_vec.squeeze().cpu().numpy()\n",
        "y_vec = y_vec.squeeze().cpu().numpy()\n",
        "\n",
        "# Plot output\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.plot(x_vec, y_vec, label='Network output')\n",
        "plt.scatter(train_df.input, train_df.label, label='Training points')\n",
        "plt.scatter(test_df.input, test_df.label, label='Test points')\n",
        "plt.xlabel('input')\n",
        "plt.ylabel('label')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
